# -*- coding: utf-8 -*-
"""RecolecciÃ³n de metrica.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fikZgL8mnmnNfnI0mW-_7fr0gfMcMjre
"""

import os
import wandb
import gdown
import numpy as np
import pandas as pd
from tqdm import tqdm
from zipfile import ZipFile
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.utils import get_custom_objects
from convRFF.models.layers.convRFF import ConvRFF
from gcpds.DataSet.convRFFds.train import get_compile_parameters

from gcpds.DataSet.infrared_thermal_feet import ModifiedInfraredThermalFeet
from gcpds.loss.dice import DiceCoefficient
from gcpds.Metrics import (Jaccard,
                           Sensitivity,
                           Specificity,
                           DiceCoefficientMetric)

# Para las metricas de otras partes
from sklearn.metrics import jaccard_score, f1_score, confusion_matrix
from tensorflow.keras import backend as K

# Para cargar los datos desde drive
from glob import glob
import shutil
from gcpds.DataSet.utils import unzip, listify

from sklearn.metrics import jaccard_score, f1_score, confusion_matrix
from gcpds.DataSet.convRFFds import data


def DowloadModels(file_path: str = "/content/Drive/MyDrive/Proyecto/Modelos.zip"):
    os.makedirs('/content/', exist_ok=True)
    models_folder = '/content/Modelos'
    if os.path.exists(models_folder):
        shutil.rmtree(models_folder)
    unzip(file_path, '/content/')


DowloadModels()

dir = {'ConvRFF': ConvRFF,
       'DiceCoefficient': DiceCoefficient,  # Loss metric
       'Jaccard': Jaccard,
       'Sensitivity': Sensitivity,
       'Specificity': Specificity,
       'DiceCoefficientMetric': DiceCoefficientMetric}  # evaluation metric

for nombre, funcion in dir.items():
    get_custom_objects().update({nombre: funcion})

model_dir = {}
for x in os.listdir("/content/Modelos/"):
    for y in os.listdir("/content/Modelos/{}/".format(x)):
        if len(os.listdir("/content/Modelos/{}/{}".format(x, y))) > 1:
            for z in os.listdir("/content/Modelos/{}/{}".format(x, y)):
                for a in tqdm(os.listdir("/content/Modelos/{}/{}/{}".format(x, y, z))):
                    model_dir[os.path.splitext(a)[0]] = tf.keras.models.load_model(
                        "/content/Modelos/{}/{}/{}/{}".format(x, y, z, a))
                    print("load {} model".format(os.path.splitext(a)[0]))
        else:
            for z in tqdm(os.listdir("/content/Modelos/{}/{}".format(x, y))):
                model_dir[os.path.splitext(z)[0]] = tf.keras.models.load_model(
                    "/content/Modelos/{}/{}/{}".format(x, y, z))
                print("load {} model".format(os.path.splitext(z)[0]))


kwargs_data_augmentationBM = dict(repeat=1,
                                  batch_size=1,
                                  shape=224,
                                  split=[0.1, 0.1]
                                  )

kwargs_data_augmentationFSL = dict(repeat=1,
                                   batch_size=1,
                                   shape=224,
                                   split=[0.1, 0.1]
                                   )

dataset = ModifiedInfraredThermalFeet
# _, _, test_datasetBM = data.get_data(dataset_class=dataset, data_augmentation=False, return_label_info=True, **kwargs_data_augmentationBM)
_, _, test_dataset = data.get_data(
    dataset_class=dataset, data_augmentation=False, return_label_info=True, **kwargs_data_augmentationFSL)


def metrics_calc(y_true, y_pred):

    y_true = tf.reshape(y_true, (1, 224, 224, 1))

    y_true = tf.cast(y_true > 0.5, tf.float32)
    y_pred = tf.cast(y_pred > 0.5, tf.float32)

    dice = DiceCoefficientMetric()
    jac = Jaccard()
    sen = Sensitivity()
    spe = Specificity()

    dice_old = dice.compute(y_true, y_pred).numpy()[0]
    jac_old = jac(y_true, y_pred).numpy()
    sen_old = sen(y_true, y_pred).numpy()
    spe_old = spe(y_true, y_pred).numpy()

    y_true = y_true.numpy().flatten()
    y_pred = y_pred.numpy().flatten()

    jac = jaccard_score(y_true, y_pred)

    dice = f1_score(y_true, y_pred)

    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()
    spe = tn/(tn+fp)
    sen = tp/(tp+fn)

    return dice, jac, sen, spe, dice_old, jac_old, sen_old, spe_old


def get_episodenk(train_dataset, nway, kshot):
    support = np.zeros([nway, kshot, 224,  224, 1], dtype=np.float32)
    smasks = np.zeros([nway, kshot,  56,   56, 1], dtype=np.float32)
    query = np.zeros([nway,         224,  224, 1], dtype=np.float32)
    qmask = np.zeros([nway,         224,  224, 1], dtype=np.float32)
    for idx in range(nway):
        for idy1 in range(kshot):
            onedata = train_dataset.batch(1).shuffle(100)
            data = onedata.take(1)
            for img, mask, id_img in data:
                img = img[0, ...]
                img = img[0, ...].numpy()
                mask = mask[0, ...]
                mask = mask[0, ...]
                mask = tf.image.resize(mask, (56, 56)).numpy()
                simg = tf.convert_to_tensor(
                    img.reshape(1, 1, 224, 224, 1), dtype=float)
                smask = tf.convert_to_tensor(
                    mask.reshape(1, 1, 56, 56, 1), dtype=float)
                support[idx, idy1] = simg
                smasks[idx, idy1] = smask
        for idy2 in range(1):
            onedata = train_dataset.batch(1).shuffle(100)
            data = onedata.take(1)
            for img, mask, id_img in data:
                img = img[0, ...]
                img = img[0, ...].numpy()
                mask = mask[0, ...]
                mask = mask[0, ...].numpy()
                qimg = tf.convert_to_tensor(
                    img.reshape(1, 224, 224, 1), dtype=float)
                qmasks = tf.convert_to_tensor(
                    mask.reshape(1, 224, 224, 1), dtype=float)
                query[idx] = qimg
                qmask[idx] = qmasks
    return support, smasks, query, qmask


def EvaluateFSL(modelname, models, test_dataset, df):
    test_dataset2 = test_dataset.batch(1)
    data_iterator = iter(test_dataset2)
    modelx = models[modelname]
    # para sacar la siguiente imagen usas este codigo
    for i in range(25):
        support, smask, _, _ = get_episodenk(test_dataset, 1, 3)
        data = next(data_iterator)
        x, y_true, id = data
        img = x[0, ...]
        img = img[0, ...].numpy()
        mask = y_true[0, ...]
        mask = mask[0, ...].numpy()
        qimg = tf.convert_to_tensor(img.reshape(1, 224, 224, 1), dtype=float)
        y_pred = modelx.predict([support, smask, qimg])
        # id es un tensor, con esto sacas el texto namas
        id = id.numpy()[0, 0]

        dice, jac, sen, spe, dice_old, jac_old, sen_old, spe_old = metrics_calc(
            y_true, y_pred)
        df.loc[len(df.index)] = [modelname, id, dice, jac, sen,
                                 spe, dice_old, jac_old, sen_old, spe_old]
    return df


def EvaluateM(modelname, models, test_dataset, df):
    test_dataset2 = test_dataset.batch(1)
    data_iterator = iter(test_dataset2)
    modelx = models[modelname]
    # para sacar la siguiente imagen usas este codigo
    for i in range(25):
        data = next(data_iterator)
        x, y_true, id = data
        x = tf.reshape(x, (1, 224, 224, 1))
        y_true = tf.reshape(y_true, (1, 224, 224, 1))

        y_pred = modelx.predict(x)

        # id es un tensor, con esto sacas el texto namas
        id = id.numpy()[0, 0]

        dice, jac, sen, spe, dice_old, jac_old, sen_old, spe_old = metrics_calc(
            y_true, y_pred)
        df.loc[len(df.index)] = [modelname, id, dice, jac, sen,
                                 spe, dice_old, jac_old, sen_old, spe_old]
    return df


df = pd.DataFrame(columns=["Model_name", "Img_ID", "Dice", "Jaccard", "Sensitivity",
                  "Specificity", "Dice_old", "Jaccard_old", "Sensitivity_old", "Specificity_old"])
for model in tqdm(model_dir):
    if model == 'FSL12' or model == 'FSL14' or model == 'FSL18':
        df = EvaluateFSL(model, model_dir, test_dataset, df)
    else:
        df = EvaluateM(model, model_dir, test_dataset, df)

df

df.to_csv("out.csv")

df = pd.read_csv("out.csv")
df.head()

df12 = pd.concat([df.loc[df["Model_name"] == 'FSL12', :],
                  df.loc[df["Model_name"] == 'f_b-A12', :],
                  df.loc[df["Model_name"] == 'f_r_s_m1-A12', :],
                  df.loc[df["Model_name"] == 'r_b-A12', :],
                  df.loc[df["Model_name"] == 'r_r_s-A12', :],
                  df.loc[df["Model_name"] == 'u_b_s_m3-A12', :],
                  df.loc[df["Model_name"] == 'f_b-NA12', :],
                  df.loc[df["Model_name"] == 'f_r_s_m1-NA12', :],
                  df.loc[df["Model_name"] == 'r_b-NA12', :],
                  df.loc[df["Model_name"] == 'r_r_s-NA12', :],
                  df.loc[df["Model_name"] == 'u_b_s_m3-NA12', :]])

df14 = pd.concat([df.loc[df["Model_name"] == 'FSL14', :],
                  df.loc[df["Model_name"] == 'f_b-A14', :],
                  df.loc[df["Model_name"] == 'f_r_s_m1-A14', :],
                  df.loc[df["Model_name"] == 'r_b-A14', :],
                  df.loc[df["Model_name"] == 'r_r_s-A14', :],
                  df.loc[df["Model_name"] == 'u_b_s_m3-A14', :],
                  df.loc[df["Model_name"] == 'f_b-NA14', :],
                  df.loc[df["Model_name"] == 'f_r_s_m1-NA14', :],
                  df.loc[df["Model_name"] == 'r_b-NA14', :],
                  df.loc[df["Model_name"] == 'r_r_s-NA14', :],
                  df.loc[df["Model_name"] == 'u_b_s_m3-NA14', :]])

df18 = pd.concat([df.loc[df["Model_name"] == 'FSL18', :],
                  df.loc[df["Model_name"] == 'f_b-A18', :],
                  df.loc[df["Model_name"] == 'f_r_s_m1-A18', :],
                  df.loc[df["Model_name"] == 'r_b-A18', :],
                  df.loc[df["Model_name"] == 'r_r_s-A18', :],
                  df.loc[df["Model_name"] == 'u_b_s_m3-A18', :],
                  df.loc[df["Model_name"] == 'f_b-NA18', :],
                  df.loc[df["Model_name"] == 'f_r_s_m1-NA18', :],
                  df.loc[df["Model_name"] == 'r_b-NA18', :],
                  df.loc[df["Model_name"] == 'r_r_s-NA18', :],
                  df.loc[df["Model_name"] == 'u_b_s_m3-NA18', :]])

column = df12.columns[3]
fig, axs = plt.subplots(figsize=(15, 15))
df12.boxplot(column=column, by='Model_name', ax=axs)
axs.set_title(column)  # Set title for each subplot
axs.set_xlabel('Group')  # Set x-axis label
axs.set_xticklabels(axs.get_xticklabels(), rotation=75)  # Rotate x-axis labels
# Adjust layout
plt.tight_layout()

# Show the plot
plt.show()

column = df14.columns[3]
fig, axs = plt.subplots(figsize=(15, 15))
df14.boxplot(column=column, by='Model_name', ax=axs)
axs.set_title(column)  # Set title for each subplot
axs.set_xlabel('Group')  # Set x-axis label
axs.set_xticklabels(axs.get_xticklabels(), rotation=75)  # Rotate x-axis labels
# Adjust layout
plt.tight_layout()

# Show the plot
plt.show()

column = df18.columns[3]
fig, axs = plt.subplots(figsize=(15, 15))
df18.boxplot(column=column, by='Model_name', ax=axs)
axs.set_title(column)  # Set title for each subplot
axs.set_xlabel('Group')  # Set x-axis label
axs.set_xticklabels(axs.get_xticklabels(), rotation=75)  # Rotate x-axis labels
# Adjust layout
plt.tight_layout()

# Show the plot
plt.show()

df2 = df12.groupby('Model_name').mean().sort_values(by="Dice", ascending=False)
df2

df2 = df14.groupby('Model_name').mean().sort_values(by="Dice", ascending=False)
df2

df2 = df18.groupby('Model_name').mean().sort_values(by="Dice", ascending=False)
df2
